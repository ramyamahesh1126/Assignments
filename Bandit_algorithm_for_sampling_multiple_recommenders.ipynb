{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bandit algorithm for sampling multiple recommenders.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMHyX+tejEfwkbw3wwI6sOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramyamahesh1126/Deep-Learning-Optional-Assignments/blob/Assignment1/Bandit_algorithm_for_sampling_multiple_recommenders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KEHR2Ui-lo8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03310b8-23d3-4554-da1b-69f7f6286843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-agents\n",
            "  Downloading tf_agents-0.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 153 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 194 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 235 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 276 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 307 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 317 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 348 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 358 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 389 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 399 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 430 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 440 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 460 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 471 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 481 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 501 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 512 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 522 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 542 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 552 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 583 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 593 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 614 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 624 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 634 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 655 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 665 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 675 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 696 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 706 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 716 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 727 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 737 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 747 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 757 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 768 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 778 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 788 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 798 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 808 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 819 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 829 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 839 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 849 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 860 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 870 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 880 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 890 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 901 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 911 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 921 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 931 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 942 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 952 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 962 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 972 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 983 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 993 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.0 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.0 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.2 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.0.0)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.17.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents) (7.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.21.6)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (0.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (1.14.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 73 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents) (3.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents) (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.5.3)\n",
            "Installing collected packages: pygame, tf-agents\n",
            "Successfully installed pygame-2.1.0 tf-agents-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3oCS94Z83Jo2"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents import tf_agent\n",
        "from tf_agents.drivers import driver\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.policies import tf_policy\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.trajectories import policy_step\n",
        "\n",
        "nest = tf.nest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TTaG2ZapQvHX"
      },
      "outputs": [],
      "source": [
        "class BanditPyEnvironment(py_environment.PyEnvironment):\n",
        "\n",
        "  def __init__(self, observation_spec, action_spec):\n",
        "    self._observation_spec = observation_spec\n",
        "    self._action_spec = action_spec\n",
        "    super(BanditPyEnvironment, self).__init__()\n",
        "\n",
        "  # Helper functions.\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _empty_observation(self):\n",
        "    return tf.nest.map_structure(lambda x: np.zeros(x.shape, x.dtype),\n",
        "                                 self.observation_spec())\n",
        "\n",
        "  # These two functions below should not be overridden by subclasses.\n",
        "  def _reset(self):\n",
        "    \"\"\"Returns a time step containing an observation.\"\"\"\n",
        "    return ts.restart(self._observe(), batch_size=self.batch_size)\n",
        "\n",
        "  def _step(self, action):\n",
        "    \"\"\"Returns a time step containing the reward for the action taken.\"\"\"\n",
        "    reward = self._apply_action(action)\n",
        "    return ts.termination(self._observe(), reward)\n",
        "\n",
        "  # These two functions below are to be implemented in subclasses.\n",
        "  @abc.abstractmethod\n",
        "  def _observe(self):\n",
        "    \"\"\"Returns an observation.\"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def _apply_action(self, action):\n",
        "    \"\"\"Applies `action` to the Environment and returns the corresponding reward.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YV6DhsSi227-"
      },
      "outputs": [],
      "source": [
        "class SimplePyEnvironment(BanditPyEnvironment):\n",
        "\n",
        "  def __init__(self):\n",
        "    action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=2, name='action')\n",
        "    observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(1,), dtype=np.int32, minimum=-2, maximum=2, name='observation')\n",
        "    super(SimplePyEnvironment, self).__init__(observation_spec, action_spec)\n",
        "\n",
        "  def _observe(self):\n",
        "    self._observation = np.random.randint(-2, 3, (1,), dtype='int32')\n",
        "    return self._observation\n",
        "\n",
        "  def _apply_action(self, action):\n",
        "    return action * self._observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Eo_uwSz2gAKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd73288-1510-49bf-b30d-5abb7d2618d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation: 1\n",
            "action: 2\n",
            "reward: 2.000000\n"
          ]
        }
      ],
      "source": [
        "environment = SimplePyEnvironment()\n",
        "observation = environment.reset().observation\n",
        "print(\"observation: %d\" % observation)\n",
        "\n",
        "action = 2 #@param\n",
        "\n",
        "print(\"action: %d\" % action)\n",
        "reward = environment.step(action).reward\n",
        "print(\"reward: %f\" % reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IPPpwSi3EtWz"
      },
      "outputs": [],
      "source": [
        "tf_environment = tf_py_environment.TFPyEnvironment(environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VpMZlplNK5ND"
      },
      "outputs": [],
      "source": [
        "class SignPolicy(tf_policy.TFPolicy):\n",
        "  def __init__(self):\n",
        "    observation_spec = tensor_spec.BoundedTensorSpec(\n",
        "        shape=(1,), dtype=tf.int32, minimum=-2, maximum=2)\n",
        "    time_step_spec = ts.time_step_spec(observation_spec)\n",
        "\n",
        "    action_spec = tensor_spec.BoundedTensorSpec(\n",
        "        shape=(), dtype=tf.int32, minimum=0, maximum=2)\n",
        "\n",
        "    super(SignPolicy, self).__init__(time_step_spec=time_step_spec,\n",
        "                                     action_spec=action_spec)\n",
        "  def _distribution(self, time_step):\n",
        "    pass\n",
        "\n",
        "  def _variables(self):\n",
        "    return ()\n",
        "\n",
        "  def _action(self, time_step, policy_state, seed):\n",
        "    observation_sign = tf.cast(tf.sign(time_step.observation[0]), dtype=tf.int32)\n",
        "    action = observation_sign + 1\n",
        "    return policy_step.PolicyStep(action, policy_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z0_5vMDCVZWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e3cfd7-3523-4bc3-e7cc-b6a3cbd306a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation:\n",
            "tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "Action:\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "Reward:\n",
            "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "sign_policy = SignPolicy()\n",
        "\n",
        "current_time_step = tf_environment.reset()\n",
        "print('Observation:')\n",
        "print (current_time_step.observation)\n",
        "action = sign_policy.action(current_time_step).action\n",
        "print('Action:')\n",
        "print (action)\n",
        "reward = tf_environment.step(action).reward\n",
        "print('Reward:')\n",
        "print(reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CiB935of-wVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fc180a-0191-48b5-ddf2-239afb29c05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: \n",
            "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
            "Next observation:\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "step = tf_environment.reset()\n",
        "action = 1\n",
        "next_step = tf_environment.step(action)\n",
        "reward = next_step.reward\n",
        "next_observation = next_step.observation\n",
        "print(\"Reward: \")\n",
        "print(reward)\n",
        "print(\"Next observation:\")\n",
        "print(next_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fte7-Mr8O0QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a6cfcb-87bd-4c49-aa09-2c8db29131af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reward sign:\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "class TwoWayPyEnvironment(BanditPyEnvironment):\n",
        "\n",
        "  def __init__(self):\n",
        "    action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=2, name='action')\n",
        "    observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(1,), dtype=np.int32, minimum=-2, maximum=2, name='observation')\n",
        "\n",
        "    # Flipping the sign with probability 1/2.\n",
        "    self._reward_sign = 2 * np.random.randint(2) - 1\n",
        "    print(\"reward sign:\")\n",
        "    print(self._reward_sign)\n",
        "\n",
        "    super(TwoWayPyEnvironment, self).__init__(observation_spec, action_spec)\n",
        "\n",
        "  def _observe(self):\n",
        "    self._observation = np.random.randint(-2, 3, (1,), dtype='int32')\n",
        "    return self._observation\n",
        "\n",
        "  def _apply_action(self, action):\n",
        "    return self._reward_sign * action * self._observation[0]\n",
        "\n",
        "two_way_tf_environment = tf_py_environment.TFPyEnvironment(TwoWayPyEnvironment())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Srm2jsGHVM8N"
      },
      "outputs": [],
      "source": [
        "class TwoWaySignPolicy(tf_policy.TFPolicy):\n",
        "  def __init__(self, situation):\n",
        "    observation_spec = tensor_spec.BoundedTensorSpec(\n",
        "        shape=(1,), dtype=tf.int32, minimum=-2, maximum=2)\n",
        "    action_spec = tensor_spec.BoundedTensorSpec(\n",
        "        shape=(), dtype=tf.int32, minimum=0, maximum=2)\n",
        "    time_step_spec = ts.time_step_spec(observation_spec)\n",
        "    self._situation = situation\n",
        "    super(TwoWaySignPolicy, self).__init__(time_step_spec=time_step_spec,\n",
        "                                           action_spec=action_spec)\n",
        "  def _distribution(self, time_step):\n",
        "    pass\n",
        "\n",
        "  def _variables(self):\n",
        "    return [self._situation]\n",
        "\n",
        "  def _action(self, time_step, policy_state, seed):\n",
        "    sign = tf.cast(tf.sign(time_step.observation[0, 0]), dtype=tf.int32)\n",
        "    def case_unknown_fn():\n",
        "      # Choose 1 so that we get information on the sign.\n",
        "      return tf.constant(1, shape=(1,))\n",
        "\n",
        "    # Choose 0 or 2, depending on the situation and the sign of the observation.\n",
        "    def case_normal_fn():\n",
        "      return tf.constant(sign + 1, shape=(1,))\n",
        "    def case_flipped_fn():\n",
        "      return tf.constant(1 - sign, shape=(1,))\n",
        "\n",
        "    cases = [(tf.equal(self._situation, 0), case_unknown_fn),\n",
        "             (tf.equal(self._situation, 1), case_normal_fn),\n",
        "             (tf.equal(self._situation, 2), case_flipped_fn)]\n",
        "    action = tf.case(cases, exclusive=True)\n",
        "    return policy_step.PolicyStep(action, policy_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7f-0W0cMbS_z"
      },
      "outputs": [],
      "source": [
        "class SignAgent(tf_agent.TFAgent):\n",
        "  def __init__(self):\n",
        "    self._situation = tf.Variable(0, dtype=tf.int32)\n",
        "    policy = TwoWaySignPolicy(self._situation)\n",
        "    time_step_spec = policy.time_step_spec\n",
        "    action_spec = policy.action_spec\n",
        "    super(SignAgent, self).__init__(time_step_spec=time_step_spec,\n",
        "                                    action_spec=action_spec,\n",
        "                                    policy=policy,\n",
        "                                    collect_policy=policy,\n",
        "                                    train_sequence_length=None)\n",
        "\n",
        "  def _initialize(self):\n",
        "    return tf.compat.v1.variables_initializer(self.variables)\n",
        "\n",
        "  def _train(self, experience, weights=None):\n",
        "    observation = experience.observation\n",
        "    action = experience.action\n",
        "    reward = experience.reward\n",
        "\n",
        "    # We only need to change the value of the situation variable if it is\n",
        "    # unknown (0) right now, and we can infer the situation only if the\n",
        "    # observation is not 0.\n",
        "    needs_action = tf.logical_and(tf.equal(self._situation, 0),\n",
        "                                  tf.not_equal(reward, 0))\n",
        "\n",
        "\n",
        "    def new_situation_fn():\n",
        "      \"\"\"This returns either 1 or 2, depending on the signs.\"\"\"\n",
        "      return (3 - tf.sign(tf.cast(observation[0, 0, 0], dtype=tf.int32) *\n",
        "                          tf.cast(action[0, 0], dtype=tf.int32) *\n",
        "                          tf.cast(reward[0, 0], dtype=tf.int32))) / 2\n",
        "\n",
        "    new_situation = tf.cond(needs_action,\n",
        "                            new_situation_fn,\n",
        "                            lambda: self._situation)\n",
        "    new_situation = tf.cast(new_situation, tf.int32)\n",
        "    tf.compat.v1.assign(self._situation, new_situation)\n",
        "    return tf_agent.LossInfo((), ())\n",
        "\n",
        "sign_agent = SignAgent()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gdSG1nv-HUJq"
      },
      "outputs": [],
      "source": [
        "# We need to add another dimension here because the agent expects the\n",
        "# trajectory of shape [batch_size, time, ...], but in this tutorial we assume\n",
        "# that both batch size and time are 1. Hence all the expand_dims.\n",
        "\n",
        "def trajectory_for_bandit(initial_step, action_step, final_step):\n",
        "  return trajectory.Trajectory(observation=tf.expand_dims(initial_step.observation, 0),\n",
        "                               action=tf.expand_dims(action_step.action, 0),\n",
        "                               policy_info=action_step.info,\n",
        "                               reward=tf.expand_dims(final_step.reward, 0),\n",
        "                               discount=tf.expand_dims(final_step.discount, 0),\n",
        "                               step_type=tf.expand_dims(initial_step.step_type, 0),\n",
        "                               next_step_type=tf.expand_dims(final_step.step_type, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LPx43dZgoyKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f97552-f17a-40d8-f77e-8d8b98295b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[1]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-1]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-1]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-2]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[1]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-2]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-1]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-2]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-2]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[1]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[0]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n",
            "Trajectory(\n",
            "{'action': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>,\n",
            " 'discount': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'next_step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[-1]]], dtype=int32)>,\n",
            " 'policy_info': (),\n",
            " 'reward': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
            " 'step_type': <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[2]], dtype=int32)>})\n"
          ]
        }
      ],
      "source": [
        "step = two_way_tf_environment.reset()\n",
        "for _ in range(10):\n",
        "  action_step = sign_agent.collect_policy.action(step)\n",
        "  next_step = two_way_tf_environment.step(action_step.action)\n",
        "  experience = trajectory_for_bandit(step, action_step, next_step)\n",
        "  print(experience)\n",
        "  sign_agent.train(experience)\n",
        "  step = next_step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oEnXUwd-nZKl"
      },
      "outputs": [],
      "source": [
        "# Imports for example.\n",
        "from tf_agents.bandits.agents import lin_ucb_agent\n",
        "from tf_agents.bandits.environments import stationary_stochastic_py_environment as sspe\n",
        "from tf_agents.bandits.metrics import tf_metrics\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gVa0hmQrpe6w"
      },
      "outputs": [],
      "source": [
        "batch_size = 2 # @param\n",
        "arm0_param = [-3, 0, 1, -2] # @param\n",
        "arm1_param = [1, -2, 3, 0] # @param\n",
        "arm2_param = [0, 0, 1, 1] # @param\n",
        "def context_sampling_fn(batch_size):\n",
        "  \"\"\"Contexts from [-10, 10]^4.\"\"\"\n",
        "  def _context_sampling_fn():\n",
        "    return np.random.randint(-10, 10, [batch_size, 4]).astype(np.float32)\n",
        "  return _context_sampling_fn\n",
        "\n",
        "class LinearNormalReward(object):\n",
        "  \"\"\"A class that acts as linear reward function when called.\"\"\"\n",
        "  def __init__(self, theta, sigma):\n",
        "    self.theta = theta\n",
        "    self.sigma = sigma\n",
        "  def __call__(self, x):\n",
        "    mu = np.dot(x, self.theta)\n",
        "    return np.random.normal(mu, self.sigma)\n",
        "\n",
        "arm0_reward_fn = LinearNormalReward(arm0_param, 1)\n",
        "arm1_reward_fn = LinearNormalReward(arm1_param, 1)\n",
        "arm2_reward_fn = LinearNormalReward(arm2_param, 1)\n",
        "\n",
        "environment = tf_py_environment.TFPyEnvironment(\n",
        "    sspe.StationaryStochasticPyEnvironment(\n",
        "        context_sampling_fn(batch_size),\n",
        "        [arm0_reward_fn, arm1_reward_fn, arm2_reward_fn],\n",
        "        batch_size=batch_size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p4XmGgIusj-K"
      },
      "outputs": [],
      "source": [
        "observation_spec = tensor_spec.TensorSpec([4], tf.float32)\n",
        "time_step_spec = ts.time_step_spec(observation_spec)\n",
        "action_spec = tensor_spec.BoundedTensorSpec(\n",
        "    dtype=tf.int32, shape=(), minimum=0, maximum=2)\n",
        "\n",
        "agent = lin_ucb_agent.LinearUCBAgent(time_step_spec=time_step_spec,\n",
        "                                     action_spec=action_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cX7MiFhNu3_L"
      },
      "outputs": [],
      "source": [
        "def compute_optimal_reward(observation):\n",
        "  expected_reward_for_arms = [\n",
        "      tf.linalg.matvec(observation, tf.cast(arm0_param, dtype=tf.float32)),\n",
        "      tf.linalg.matvec(observation, tf.cast(arm1_param, dtype=tf.float32)),\n",
        "      tf.linalg.matvec(observation, tf.cast(arm2_param, dtype=tf.float32))]\n",
        "  optimal_action_reward = tf.reduce_max(expected_reward_for_arms, axis=0)\n",
        "  return optimal_action_reward\n",
        "\n",
        "regret_metric = tf_metrics.RegretMetric(compute_optimal_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4Ggn45g62DWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "14fafeae-e761-487f-bf70-6313cfbb2ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-0cbf469acdfe>:21: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of Iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_iterations = 90 # @param\n",
        "steps_per_loop = 1 # @param\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.policy.trajectory_spec,\n",
        "    batch_size=batch_size,\n",
        "    max_length=steps_per_loop)\n",
        "\n",
        "observers = [replay_buffer.add_batch, regret_metric]\n",
        "\n",
        "driver = dynamic_step_driver.DynamicStepDriver(\n",
        "    env=environment,\n",
        "    policy=agent.collect_policy,\n",
        "    num_steps=steps_per_loop * batch_size,\n",
        "    observers=observers)\n",
        "\n",
        "regret_values = []\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "  driver.run()\n",
        "  loss_info = agent.train(replay_buffer.gather_all())\n",
        "  replay_buffer.clear()\n",
        "  regret_values.append(regret_metric.result())\n",
        "\n",
        "plt.plot(regret_values)\n",
        "plt.ylabel('Average Regret')\n",
        "plt.xlabel('Number of Iterations')"
      ]
    }
  ]
}