{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPU35O0E+oumIbsr4q3IL0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramyamahesh1126/Assignments/blob/Assignment2/GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5UupkDpdZKSB",
        "outputId": "f848998f-b65b-44b0-c73f-869ce63ca043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_UGvOahDZKSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318c5cf2-bbe3-4b34-c48b-25b2f9b6d2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
        "# Files to download\n",
        "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
        "\n",
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tSFHYvNhZKSE"
      },
      "outputs": [],
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(c_in, c_out)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
        "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
        "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections. \n",
        "                         Shape: [batch_size, num_nodes, num_nodes]\n",
        "        \"\"\"\n",
        "        # Num neighbours = number of incoming edges\n",
        "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
        "        node_feats = node_feats / num_neighbours\n",
        "        return node_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hT_T2vXTZKSF",
        "outputId": "dae07b3d-7949-43b3-b4d8-7b5b2f31b644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features:\n",
            " tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "\n",
            "Adjacency matrix:\n",
            " tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
        "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
        "                            [1, 1, 1, 1],\n",
        "                            [0, 1, 1, 1],\n",
        "                            [0, 1, 1, 1]]])\n",
        "\n",
        "print(\"Node features:\\n\", node_feats)\n",
        "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LAxpUr0dZKSF",
        "outputId": "65eb907f-0595-4151-ef8e-dd3852690264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Input features tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "Output features tensor([[[1., 2.],\n",
            "         [3., 4.],\n",
            "         [4., 5.],\n",
            "         [4., 5.]]])\n"
          ]
        }
      ],
      "source": [
        "layer = GCNLayer(c_in=2, c_out=2)\n",
        "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
        "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix)\n",
        "\n",
        "print(\"Adjacency matrix\", adj_matrix)\n",
        "print(\"Input features\", node_feats)\n",
        "print(\"Output features\", out_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3wqxkIAqZKSG"
      },
      "outputs": [],
      "source": [
        "class GATLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimensionality of input features\n",
        "            c_out - Dimensionality of output features\n",
        "            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The \n",
        "                        output features are equally split up over the heads if concat_heads=True.\n",
        "            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n",
        "            alpha - Negative slope of the LeakyReLU activation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        if self.concat_heads:\n",
        "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
        "            c_out = c_out // num_heads\n",
        "        \n",
        "        # Sub-modules and parameters needed in the layer\n",
        "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
        "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # One per head\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "        \n",
        "        # Initialization from the original implementation\n",
        "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "        \n",
        "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Input features of the node. Shape: [batch_size, c_in]\n",
        "            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
        "            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n",
        "        \"\"\"\n",
        "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
        "        \n",
        "        # Apply linear layer and sort nodes by head\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
        "        \n",
        "        # We need to calculate the attention logits for every edge in the adjacency matrix \n",
        "        # Doing this on all possible combinations of nodes is very expensive\n",
        "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
        "        edges = adj_matrix.nonzero(as_tuple=False) # Returns indices where the adjacency matrix is not 0 => edges\n",
        "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
        "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
        "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
        "        a_input = torch.cat([\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
        "        ], dim=-1) # Index select returns a tensor with node_feats_flat being indexed at the desired positions along dim=0\n",
        "        \n",
        "        # Calculate attention MLP output (independent for each head)\n",
        "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a) \n",
        "        attn_logits = self.leakyrelu(attn_logits)\n",
        "        \n",
        "        # Map list of attention values back into a matrix\n",
        "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n",
        "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
        "        \n",
        "        # Weighted average of attention\n",
        "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
        "        if print_attn_probs:\n",
        "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
        "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
        "        \n",
        "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
        "        if self.concat_heads:\n",
        "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
        "        else:\n",
        "            node_feats = node_feats.mean(dim=2)\n",
        "        \n",
        "        return node_feats "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZemRPg18ZKSG",
        "outputId": "569a249b-d34b-489b-ffad-8feea4a3063a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention probs\n",
            " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
            "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
            "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
            "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
            "\n",
            "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
            "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
            "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
            "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
            "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Input features tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "Output features tensor([[[1.2913, 1.9800],\n",
            "         [4.2344, 3.7725],\n",
            "         [4.6798, 4.8362],\n",
            "         [4.5043, 4.7351]]])\n"
          ]
        }
      ],
      "source": [
        "layer = GATLayer(2, 2, num_heads=2)\n",
        "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
        "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
        "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
        "\n",
        "print(\"Adjacency matrix\", adj_matrix)\n",
        "print(\"Input features\", node_feats)\n",
        "print(\"Output features\", out_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fpfoOQf-ZKSG",
        "outputId": "167678c7-dbf9-4f1f-f785-73d0862ee2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=6a6c922427239c1d5d0e7c5a108cae3319e69936a3c93f93dfa8fcfb6526a894\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ],
      "source": [
        "# torch geometric\n",
        "try: \n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version. \n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details \n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric \n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3OnZiHxZKSH"
      },
      "source": [
        "## Experiments on graph structures\n",
        "\n",
        "Tasks on graph-structured data can be grouped into three groups: node-level, edge-level and graph-level. The different levels describe on which level we want to perform classification/regression. We will discuss all three types in more detail below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9t1-fZTZKSH"
      },
      "source": [
        "### Node-level tasks: Semi-supervised node classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ebCvZTLeZKSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc16f753-7c45-413a-de90-dbf23d1505e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyB-HOJ7ZKSH"
      },
      "source": [
        "Let's look at how PyTorch Geometric represents the graph data. Note that although we have a single graph, PyTorch Geometric returns a dataset for compatibility to other datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pyRmnnNvZKSH",
        "outputId": "2b9bc7c9-6d38-47b1-96c3-5a5f9de47f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "cora_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r5jYStGFZKSH"
      },
      "outputs": [],
      "source": [
        "class GNNModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of \"hidden\" graph layers\n",
        "            layer_name - String of the graph layer to use\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "        \n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                gnn_layer(in_channels=in_channels, \n",
        "                          out_channels=out_channels,\n",
        "                          **kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [gnn_layer(in_channels=in_channels, \n",
        "                             out_channels=c_out,\n",
        "                             **kwargs)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "        \"\"\"\n",
        "        for l in self.layers:\n",
        "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
        "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
        "            # we can simply check the class type.\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index)\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SEcAaiSPZKSH"
      },
      "outputs": [],
      "source": [
        "class MLPModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of hidden layers\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                nn.Linear(in_channels, out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [nn.Linear(in_channels, c_out)]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "        \"\"\"\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xBWoeBEZKSH"
      },
      "source": [
        "Finally, we can merge the models into a PyTorch Lightning module which handles the training, validation, and testing for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CXXNbZ-yZKSH"
      },
      "outputs": [],
      "source": [
        "class NodeLevelGNN(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, model_name, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        if model_name == \"MLP\":\n",
        "            self.model = MLPModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = GNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.model(x, edge_index)\n",
        "        \n",
        "        # Only calculate the loss on the nodes corresponding to the mask\n",
        "        if mode == \"train\":\n",
        "            mask = data.train_mask\n",
        "        elif mode == \"val\":\n",
        "            mask = data.val_mask\n",
        "        elif mode == \"test\":\n",
        "            mask = data.test_mask\n",
        "        else:\n",
        "            assert False, f\"Unknown forward mode: {mode}\"\n",
        "        \n",
        "        loss = self.loss_module(x[mask], data.y[mask])\n",
        "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We use SGD here, but Adam works as well \n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6Wa0NGpcZKSI"
      },
      "outputs": [],
      "source": [
        "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
        "    \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
        "                         max_epochs=200,\n",
        "                         progress_bar_refresh_rate=0) # 0 because epoch size is 1\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything()\n",
        "        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
        "        trainer.fit(model, node_data_loader, node_data_loader)\n",
        "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    \n",
        "    # Test best model on the test set\n",
        "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
        "    batch = next(iter(node_data_loader))\n",
        "    batch = batch.to(model.device)\n",
        "    _, train_acc = model.forward(batch, mode=\"train\")\n",
        "    _, val_acc = model.forward(batch, mode=\"val\")\n",
        "    result = {\"train\": train_acc,\n",
        "              \"val\": val_acc,\n",
        "              \"test\": test_result[0]['test_acc']}\n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXeB2e-LZKSI"
      },
      "source": [
        "Finally, we can train our models. First, let's train the simple MLP:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LCfSAeNVZKSI"
      },
      "outputs": [],
      "source": [
        "# Small function for printing the test scores\n",
        "def print_results(result_dict):\n",
        "    if \"train\" in result_dict:\n",
        "        print(f\"Train accuracy: {(100.0*result_dict['train']):4.2f}%\")\n",
        "    if \"val\" in result_dict:\n",
        "        print(f\"Val accuracy:   {(100.0*result_dict['val']):4.2f}%\")\n",
        "    print(f\"Test accuracy:  {(100.0*result_dict['test']):4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dwiTkizaZKSI",
        "outputId": "70ac0ee0-586e-440e-8b71-42488cba03ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: ../saved_models/tutorial7/NodeLevelMLP/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 97.14%\n",
            "Val accuracy:   54.60%\n",
            "Test accuracy:  60.60%\n"
          ]
        }
      ],
      "source": [
        "node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "\n",
        "print_results(node_mlp_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OABtSZhRZKSI"
      },
      "source": [
        "Although the MLP can overfit on the training dataset because of the high-dimensional input features, it does not perform too well on the test set. Let's see if we can beat this score with our graph networks:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv\n",
        "}"
      ],
      "metadata": {
        "id": "4OFgAdtxcVa5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iDiQSqXNZKSI",
        "outputId": "b3f1158c-3957-467f-9032-547ccc5e9ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: ../saved_models/tutorial7/NodeLevelGNN/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n",
            "Train accuracy: 100.00%\n",
            "Val accuracy:   78.60%\n",
            "Test accuracy:  82.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n"
          ]
        }
      ],
      "source": [
        "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
        "                                                        layer_name=\"GCN\",\n",
        "                                                        dataset=cora_dataset, \n",
        "                                                        c_hidden=16, \n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "print_results(node_gnn_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_1c09C6ZKSI"
      },
      "source": [
        "### Edge-level tasks: Link prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb6UvgV1ZKSI"
      },
      "source": [
        "### Graph-level tasks: Graph classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qcmmSvx6ZKSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e709242d-2a6a-4f9a-9001-642bcf137a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting ../data/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KFVNJ4PZKSI"
      },
      "source": [
        "Let's look at some statistics for the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ODSsOtX0ZKSI",
        "outputId": "603940e3-415c-41fa-a9d5-aef364cae3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
            "Length: 188\n",
            "Average label: 0.66\n"
          ]
        }
      ],
      "source": [
        "print(\"Data object:\", tu_dataset.data)\n",
        "print(\"Length:\", len(tu_dataset))\n",
        "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IalKDOBJZKSJ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "tu_dataset.shuffle()\n",
        "train_dataset = tu_dataset[:150]\n",
        "test_dataset = tu_dataset[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8WTrYVZgZKSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc05454-9873-430b-e1c2-57dc69630dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
        "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7t22WzZKSJ"
      },
      "source": [
        "Let's load a batch below to see the batching in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U8py7meTZKSJ",
        "outputId": "a764e4e1-572f-4c43-97fc-322cfe4f95ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
            "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(graph_test_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FVuTZuvSZKSJ"
      },
      "outputs": [],
      "source": [
        "class GraphGNNModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of output features (usually number of classes)\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the GNNModel object\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.GNN = GNNModel(c_in=c_in, \n",
        "                            c_hidden=c_hidden, \n",
        "                            c_out=c_hidden, # Not our prediction output yet!\n",
        "                            **kwargs)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dp_rate_linear),\n",
        "            nn.Linear(c_hidden, c_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "        \"\"\"\n",
        "        x = self.GNN(x, edge_index)\n",
        "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq23wZ6wZKSJ"
      },
      "source": [
        "Finally, we can create a PyTorch Lightning module to handle the training. It is similar to the modules we have seen before and does nothing surprising in terms of training. As we have a binary classification task, we use the Binary Cross Entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vImENfQ6ZKSJ"
      },
      "outputs": [],
      "source": [
        "class GraphLevelGNN(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.model = GraphGNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
        "        x = self.model(x, edge_index, batch_idx)\n",
        "        x = x.squeeze(dim=-1)\n",
        "        \n",
        "        if self.hparams.c_out == 1:\n",
        "            preds = (x > 0).float()\n",
        "            data.y = data.y.float()\n",
        "        else:\n",
        "            preds = x.argmax(dim=-1)\n",
        "        loss = self.loss_module(x, data.y)\n",
        "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyDOAYz6ZKSJ"
      },
      "source": [
        "Below we train the model on our dataset. It resembles the typical training functions we have seen so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CMszihfHZKSJ"
      },
      "outputs": [],
      "source": [
        "def train_graph_classifier(model_name, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
        "                         max_epochs=500,\n",
        "                         progress_bar_refresh_rate=0)\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)\n",
        "        model = GraphLevelGNN(c_in=tu_dataset.num_node_features, \n",
        "                              c_out=1 if tu_dataset.num_classes==2 else tu_dataset.num_classes, \n",
        "                              **model_kwargs)\n",
        "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    # Test best model on validation and test set\n",
        "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
        "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']} \n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKKKd9kMZKSJ"
      },
      "source": [
        "Finally, let's perform the training and testing. Feel free to experiment with different GNN layers, hyperparameters, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "id": "TpwxrdBhZKSJ",
        "outputId": "db3008c7-5c3e-402b-fcb8-c94d61306560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: ../saved_models/tutorial7/GraphLevelGraphConv/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        }
      ],
      "source": [
        "model, result = train_graph_classifier(model_name=\"GraphConv\", \n",
        "                                       c_hidden=256, \n",
        "                                       layer_name=\"GraphConv\", \n",
        "                                       num_layers=3, \n",
        "                                       dp_rate_linear=0.5,\n",
        "                                       dp_rate=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z5YpGTFtZKSJ",
        "outputId": "ba4c0650-4c0c-42c4-ad12-4cfe3f15316a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train performance: 93.28%\n",
            "Test performance:  92.11%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
        "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
      ]
    }
  ]
}